{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "To fetch a pail of water\\n\n",
    "Jack fell down and broke his crown\\n\n",
    "And Jill came tumbling after\\n \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded = tokenizer.texts_to_sequences([data])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 22\n"
     ]
    }
   ],
   "source": [
    "# determine the vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 24\n"
     ]
    }
   ],
   "source": [
    "# create word -> word sequences\n",
    "sequences = list()\n",
    "for i in range(1, len(encoded)):\n",
    "    sequence = encoded[i-1:i+1]\n",
    "    sequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and y elements\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,0],sequences[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def define_model(vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 10, input_length=1))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    \n",
    "    # compile network\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # summarize defined model\n",
    "    model.summary()\n",
    "    #plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1, 10)             220       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 22)                1122      \n",
      "=================================================================\n",
      "Total params: 13,542\n",
      "Trainable params: 13,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      " - 3s - loss: 3.0907 - acc: 0.0833\n",
      "Epoch 2/500\n",
      " - 0s - loss: 3.0900 - acc: 0.0417\n",
      "Epoch 3/500\n",
      " - 0s - loss: 3.0893 - acc: 0.0833\n",
      "Epoch 4/500\n",
      " - 0s - loss: 3.0885 - acc: 0.1250\n",
      "Epoch 5/500\n",
      " - 0s - loss: 3.0878 - acc: 0.1250\n",
      "Epoch 6/500\n",
      " - 0s - loss: 3.0870 - acc: 0.1250\n",
      "Epoch 7/500\n",
      " - 0s - loss: 3.0863 - acc: 0.1250\n",
      "Epoch 8/500\n",
      " - 0s - loss: 3.0856 - acc: 0.1250\n",
      "Epoch 9/500\n",
      " - 0s - loss: 3.0848 - acc: 0.1250\n",
      "Epoch 10/500\n",
      " - 0s - loss: 3.0840 - acc: 0.1250\n",
      "Epoch 11/500\n",
      " - 0s - loss: 3.0833 - acc: 0.1250\n",
      "Epoch 12/500\n",
      " - 0s - loss: 3.0825 - acc: 0.1250\n",
      "Epoch 13/500\n",
      " - 0s - loss: 3.0817 - acc: 0.1250\n",
      "Epoch 14/500\n",
      " - 0s - loss: 3.0809 - acc: 0.1250\n",
      "Epoch 15/500\n",
      " - 0s - loss: 3.0800 - acc: 0.1250\n",
      "Epoch 16/500\n",
      " - 0s - loss: 3.0792 - acc: 0.1250\n",
      "Epoch 17/500\n",
      " - 0s - loss: 3.0784 - acc: 0.1250\n",
      "Epoch 18/500\n",
      " - 0s - loss: 3.0775 - acc: 0.1250\n",
      "Epoch 19/500\n",
      " - 0s - loss: 3.0766 - acc: 0.1250\n",
      "Epoch 20/500\n",
      " - 0s - loss: 3.0757 - acc: 0.1250\n",
      "Epoch 21/500\n",
      " - 0s - loss: 3.0748 - acc: 0.1250\n",
      "Epoch 22/500\n",
      " - 0s - loss: 3.0738 - acc: 0.1250\n",
      "Epoch 23/500\n",
      " - 0s - loss: 3.0728 - acc: 0.1250\n",
      "Epoch 24/500\n",
      " - 0s - loss: 3.0718 - acc: 0.1250\n",
      "Epoch 25/500\n",
      " - 0s - loss: 3.0708 - acc: 0.1250\n",
      "Epoch 26/500\n",
      " - 0s - loss: 3.0697 - acc: 0.1250\n",
      "Epoch 27/500\n",
      " - 0s - loss: 3.0687 - acc: 0.1250\n",
      "Epoch 28/500\n",
      " - 0s - loss: 3.0675 - acc: 0.1250\n",
      "Epoch 29/500\n",
      " - 0s - loss: 3.0664 - acc: 0.1250\n",
      "Epoch 30/500\n",
      " - 0s - loss: 3.0652 - acc: 0.1250\n",
      "Epoch 31/500\n",
      " - 0s - loss: 3.0640 - acc: 0.1250\n",
      "Epoch 32/500\n",
      " - 0s - loss: 3.0628 - acc: 0.1250\n",
      "Epoch 33/500\n",
      " - 0s - loss: 3.0615 - acc: 0.1250\n",
      "Epoch 34/500\n",
      " - 0s - loss: 3.0602 - acc: 0.1250\n",
      "Epoch 35/500\n",
      " - 0s - loss: 3.0589 - acc: 0.1250\n",
      "Epoch 36/500\n",
      " - 0s - loss: 3.0575 - acc: 0.1250\n",
      "Epoch 37/500\n",
      " - 0s - loss: 3.0561 - acc: 0.1250\n",
      "Epoch 38/500\n",
      " - 0s - loss: 3.0546 - acc: 0.1250\n",
      "Epoch 39/500\n",
      " - 0s - loss: 3.0531 - acc: 0.1250\n",
      "Epoch 40/500\n",
      " - 0s - loss: 3.0515 - acc: 0.1250\n",
      "Epoch 41/500\n",
      " - 0s - loss: 3.0500 - acc: 0.1250\n",
      "Epoch 42/500\n",
      " - 0s - loss: 3.0483 - acc: 0.1250\n",
      "Epoch 43/500\n",
      " - 0s - loss: 3.0466 - acc: 0.1250\n",
      "Epoch 44/500\n",
      " - 0s - loss: 3.0449 - acc: 0.1250\n",
      "Epoch 45/500\n",
      " - 0s - loss: 3.0431 - acc: 0.1250\n",
      "Epoch 46/500\n",
      " - 0s - loss: 3.0413 - acc: 0.1250\n",
      "Epoch 47/500\n",
      " - 0s - loss: 3.0394 - acc: 0.1250\n",
      "Epoch 48/500\n",
      " - 0s - loss: 3.0374 - acc: 0.1250\n",
      "Epoch 49/500\n",
      " - 0s - loss: 3.0354 - acc: 0.1250\n",
      "Epoch 50/500\n",
      " - 0s - loss: 3.0333 - acc: 0.1250\n",
      "Epoch 51/500\n",
      " - 0s - loss: 3.0312 - acc: 0.1250\n",
      "Epoch 52/500\n",
      " - 0s - loss: 3.0290 - acc: 0.1250\n",
      "Epoch 53/500\n",
      " - 0s - loss: 3.0268 - acc: 0.1250\n",
      "Epoch 54/500\n",
      " - 0s - loss: 3.0245 - acc: 0.1250\n",
      "Epoch 55/500\n",
      " - 0s - loss: 3.0221 - acc: 0.1250\n",
      "Epoch 56/500\n",
      " - 0s - loss: 3.0196 - acc: 0.1250\n",
      "Epoch 57/500\n",
      " - 0s - loss: 3.0171 - acc: 0.2083\n",
      "Epoch 58/500\n",
      " - 0s - loss: 3.0145 - acc: 0.2083\n",
      "Epoch 59/500\n",
      " - 0s - loss: 3.0119 - acc: 0.2083\n",
      "Epoch 60/500\n",
      " - 0s - loss: 3.0091 - acc: 0.2083\n",
      "Epoch 61/500\n",
      " - 0s - loss: 3.0063 - acc: 0.2083\n",
      "Epoch 62/500\n",
      " - 0s - loss: 3.0034 - acc: 0.2083\n",
      "Epoch 63/500\n",
      " - 0s - loss: 3.0004 - acc: 0.2083\n",
      "Epoch 64/500\n",
      " - 0s - loss: 2.9974 - acc: 0.2083\n",
      "Epoch 65/500\n",
      " - 0s - loss: 2.9942 - acc: 0.2083\n",
      "Epoch 66/500\n",
      " - 0s - loss: 2.9910 - acc: 0.2083\n",
      "Epoch 67/500\n",
      " - 0s - loss: 2.9877 - acc: 0.2083\n",
      "Epoch 68/500\n",
      " - 0s - loss: 2.9842 - acc: 0.2083\n",
      "Epoch 69/500\n",
      " - 0s - loss: 2.9807 - acc: 0.2083\n",
      "Epoch 70/500\n",
      " - 0s - loss: 2.9771 - acc: 0.2083\n",
      "Epoch 71/500\n",
      " - 0s - loss: 2.9734 - acc: 0.2083\n",
      "Epoch 72/500\n",
      " - 0s - loss: 2.9696 - acc: 0.2083\n",
      "Epoch 73/500\n",
      " - 0s - loss: 2.9657 - acc: 0.2083\n",
      "Epoch 74/500\n",
      " - 0s - loss: 2.9617 - acc: 0.2083\n",
      "Epoch 75/500\n",
      " - 0s - loss: 2.9576 - acc: 0.2083\n",
      "Epoch 76/500\n",
      " - 0s - loss: 2.9533 - acc: 0.2083\n",
      "Epoch 77/500\n",
      " - 0s - loss: 2.9490 - acc: 0.2083\n",
      "Epoch 78/500\n",
      " - 0s - loss: 2.9445 - acc: 0.2083\n",
      "Epoch 79/500\n",
      " - 0s - loss: 2.9399 - acc: 0.2083\n",
      "Epoch 80/500\n",
      " - 0s - loss: 2.9352 - acc: 0.2083\n",
      "Epoch 81/500\n",
      " - 0s - loss: 2.9304 - acc: 0.2083\n",
      "Epoch 82/500\n",
      " - 0s - loss: 2.9255 - acc: 0.2083\n",
      "Epoch 83/500\n",
      " - 0s - loss: 2.9204 - acc: 0.2083\n",
      "Epoch 84/500\n",
      " - 0s - loss: 2.9152 - acc: 0.2083\n",
      "Epoch 85/500\n",
      " - 0s - loss: 2.9099 - acc: 0.2083\n",
      "Epoch 86/500\n",
      " - 0s - loss: 2.9044 - acc: 0.2083\n",
      "Epoch 87/500\n",
      " - 0s - loss: 2.8988 - acc: 0.2083\n",
      "Epoch 88/500\n",
      " - 0s - loss: 2.8931 - acc: 0.2083\n",
      "Epoch 89/500\n",
      " - 0s - loss: 2.8872 - acc: 0.2083\n",
      "Epoch 90/500\n",
      " - 0s - loss: 2.8812 - acc: 0.2083\n",
      "Epoch 91/500\n",
      " - 0s - loss: 2.8750 - acc: 0.2083\n",
      "Epoch 92/500\n",
      " - 0s - loss: 2.8687 - acc: 0.2083\n",
      "Epoch 93/500\n",
      " - 0s - loss: 2.8622 - acc: 0.2083\n",
      "Epoch 94/500\n",
      " - 0s - loss: 2.8556 - acc: 0.2083\n",
      "Epoch 95/500\n",
      " - 0s - loss: 2.8488 - acc: 0.2083\n",
      "Epoch 96/500\n",
      " - 0s - loss: 2.8419 - acc: 0.2083\n",
      "Epoch 97/500\n",
      " - 0s - loss: 2.8348 - acc: 0.2083\n",
      "Epoch 98/500\n",
      " - 0s - loss: 2.8276 - acc: 0.2083\n",
      "Epoch 99/500\n",
      " - 0s - loss: 2.8202 - acc: 0.2083\n",
      "Epoch 100/500\n",
      " - 0s - loss: 2.8126 - acc: 0.2083\n",
      "Epoch 101/500\n",
      " - 0s - loss: 2.8048 - acc: 0.2083\n",
      "Epoch 102/500\n",
      " - 0s - loss: 2.7969 - acc: 0.2083\n",
      "Epoch 103/500\n",
      " - 0s - loss: 2.7888 - acc: 0.2083\n",
      "Epoch 104/500\n",
      " - 0s - loss: 2.7806 - acc: 0.2083\n",
      "Epoch 105/500\n",
      " - 0s - loss: 2.7722 - acc: 0.2083\n",
      "Epoch 106/500\n",
      " - 0s - loss: 2.7636 - acc: 0.2083\n",
      "Epoch 107/500\n",
      " - 0s - loss: 2.7548 - acc: 0.2083\n",
      "Epoch 108/500\n",
      " - 0s - loss: 2.7459 - acc: 0.2083\n",
      "Epoch 109/500\n",
      " - 0s - loss: 2.7367 - acc: 0.2083\n",
      "Epoch 110/500\n",
      " - 0s - loss: 2.7274 - acc: 0.2083\n",
      "Epoch 111/500\n",
      " - 0s - loss: 2.7179 - acc: 0.2083\n",
      "Epoch 112/500\n",
      " - 0s - loss: 2.7083 - acc: 0.2083\n",
      "Epoch 113/500\n",
      " - 0s - loss: 2.6984 - acc: 0.2500\n",
      "Epoch 114/500\n",
      " - 0s - loss: 2.6885 - acc: 0.2500\n",
      "Epoch 115/500\n",
      " - 0s - loss: 2.6783 - acc: 0.2500\n",
      "Epoch 116/500\n",
      " - 0s - loss: 2.6679 - acc: 0.2500\n",
      "Epoch 117/500\n",
      " - 0s - loss: 2.6574 - acc: 0.2500\n",
      "Epoch 118/500\n",
      " - 0s - loss: 2.6467 - acc: 0.2500\n",
      "Epoch 119/500\n",
      " - 0s - loss: 2.6358 - acc: 0.2500\n",
      "Epoch 120/500\n",
      " - 0s - loss: 2.6248 - acc: 0.2500\n",
      "Epoch 121/500\n",
      " - 0s - loss: 2.6136 - acc: 0.2917\n",
      "Epoch 122/500\n",
      " - 0s - loss: 2.6022 - acc: 0.2917\n",
      "Epoch 123/500\n",
      " - 0s - loss: 2.5907 - acc: 0.2917\n",
      "Epoch 124/500\n",
      " - 0s - loss: 2.5790 - acc: 0.2917\n",
      "Epoch 125/500\n",
      " - 0s - loss: 2.5672 - acc: 0.2917\n",
      "Epoch 126/500\n",
      " - 0s - loss: 2.5551 - acc: 0.2917\n",
      "Epoch 127/500\n",
      " - 0s - loss: 2.5430 - acc: 0.2917\n",
      "Epoch 128/500\n",
      " - 0s - loss: 2.5307 - acc: 0.2917\n",
      "Epoch 129/500\n",
      " - 0s - loss: 2.5182 - acc: 0.3333\n",
      "Epoch 130/500\n",
      " - 0s - loss: 2.5055 - acc: 0.3333\n",
      "Epoch 131/500\n",
      " - 0s - loss: 2.4927 - acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/500\n",
      " - 0s - loss: 2.4798 - acc: 0.3333\n",
      "Epoch 133/500\n",
      " - 0s - loss: 2.4667 - acc: 0.3333\n",
      "Epoch 134/500\n",
      " - 0s - loss: 2.4535 - acc: 0.3333\n",
      "Epoch 135/500\n",
      " - 0s - loss: 2.4402 - acc: 0.3333\n",
      "Epoch 136/500\n",
      " - 0s - loss: 2.4267 - acc: 0.3333\n",
      "Epoch 137/500\n",
      " - 0s - loss: 2.4132 - acc: 0.3333\n",
      "Epoch 138/500\n",
      " - 0s - loss: 2.3995 - acc: 0.3333\n",
      "Epoch 139/500\n",
      " - 0s - loss: 2.3857 - acc: 0.3333\n",
      "Epoch 140/500\n",
      " - 0s - loss: 2.3718 - acc: 0.3333\n",
      "Epoch 141/500\n",
      " - 0s - loss: 2.3578 - acc: 0.3333\n",
      "Epoch 142/500\n",
      " - 0s - loss: 2.3437 - acc: 0.3333\n",
      "Epoch 143/500\n",
      " - 0s - loss: 2.3295 - acc: 0.3750\n",
      "Epoch 144/500\n",
      " - 0s - loss: 2.3152 - acc: 0.3750\n",
      "Epoch 145/500\n",
      " - 0s - loss: 2.3008 - acc: 0.3750\n",
      "Epoch 146/500\n",
      " - 0s - loss: 2.2864 - acc: 0.3750\n",
      "Epoch 147/500\n",
      " - 0s - loss: 2.2719 - acc: 0.4167\n",
      "Epoch 148/500\n",
      " - 0s - loss: 2.2573 - acc: 0.4167\n",
      "Epoch 149/500\n",
      " - 0s - loss: 2.2427 - acc: 0.4167\n",
      "Epoch 150/500\n",
      " - 0s - loss: 2.2280 - acc: 0.4167\n",
      "Epoch 151/500\n",
      " - 0s - loss: 2.2132 - acc: 0.4167\n",
      "Epoch 152/500\n",
      " - 0s - loss: 2.1984 - acc: 0.4167\n",
      "Epoch 153/500\n",
      " - 0s - loss: 2.1836 - acc: 0.4167\n",
      "Epoch 154/500\n",
      " - 0s - loss: 2.1686 - acc: 0.4167\n",
      "Epoch 155/500\n",
      " - 0s - loss: 2.1537 - acc: 0.4167\n",
      "Epoch 156/500\n",
      " - 0s - loss: 2.1387 - acc: 0.4167\n",
      "Epoch 157/500\n",
      " - 0s - loss: 2.1238 - acc: 0.4167\n",
      "Epoch 158/500\n",
      " - 0s - loss: 2.1087 - acc: 0.4167\n",
      "Epoch 159/500\n",
      " - 0s - loss: 2.0937 - acc: 0.4167\n",
      "Epoch 160/500\n",
      " - 0s - loss: 2.0786 - acc: 0.4167\n",
      "Epoch 161/500\n",
      " - 0s - loss: 2.0635 - acc: 0.4167\n",
      "Epoch 162/500\n",
      " - 0s - loss: 2.0484 - acc: 0.4167\n",
      "Epoch 163/500\n",
      " - 0s - loss: 2.0333 - acc: 0.4583\n",
      "Epoch 164/500\n",
      " - 0s - loss: 2.0183 - acc: 0.4583\n",
      "Epoch 165/500\n",
      " - 0s - loss: 2.0032 - acc: 0.5000\n",
      "Epoch 166/500\n",
      " - 0s - loss: 1.9881 - acc: 0.5000\n",
      "Epoch 167/500\n",
      " - 0s - loss: 1.9730 - acc: 0.5000\n",
      "Epoch 168/500\n",
      " - 0s - loss: 1.9579 - acc: 0.5000\n",
      "Epoch 169/500\n",
      " - 0s - loss: 1.9429 - acc: 0.5000\n",
      "Epoch 170/500\n",
      " - 0s - loss: 1.9278 - acc: 0.5000\n",
      "Epoch 171/500\n",
      " - 0s - loss: 1.9128 - acc: 0.5000\n",
      "Epoch 172/500\n",
      " - 0s - loss: 1.8978 - acc: 0.5000\n",
      "Epoch 173/500\n",
      " - 0s - loss: 1.8828 - acc: 0.5000\n",
      "Epoch 174/500\n",
      " - 0s - loss: 1.8678 - acc: 0.5000\n",
      "Epoch 175/500\n",
      " - 0s - loss: 1.8529 - acc: 0.5417\n",
      "Epoch 176/500\n",
      " - 0s - loss: 1.8380 - acc: 0.5417\n",
      "Epoch 177/500\n",
      " - 0s - loss: 1.8231 - acc: 0.5417\n",
      "Epoch 178/500\n",
      " - 0s - loss: 1.8082 - acc: 0.5417\n",
      "Epoch 179/500\n",
      " - 0s - loss: 1.7934 - acc: 0.5833\n",
      "Epoch 180/500\n",
      " - 0s - loss: 1.7786 - acc: 0.6250\n",
      "Epoch 181/500\n",
      " - 0s - loss: 1.7638 - acc: 0.7083\n",
      "Epoch 182/500\n",
      " - 0s - loss: 1.7491 - acc: 0.7083\n",
      "Epoch 183/500\n",
      " - 0s - loss: 1.7345 - acc: 0.7083\n",
      "Epoch 184/500\n",
      " - 0s - loss: 1.7199 - acc: 0.7083\n",
      "Epoch 185/500\n",
      " - 0s - loss: 1.7053 - acc: 0.7083\n",
      "Epoch 186/500\n",
      " - 0s - loss: 1.6907 - acc: 0.7083\n",
      "Epoch 187/500\n",
      " - 0s - loss: 1.6762 - acc: 0.7083\n",
      "Epoch 188/500\n",
      " - 0s - loss: 1.6617 - acc: 0.7083\n",
      "Epoch 189/500\n",
      " - 0s - loss: 1.6473 - acc: 0.7083\n",
      "Epoch 190/500\n",
      " - 0s - loss: 1.6329 - acc: 0.7083\n",
      "Epoch 191/500\n",
      " - 0s - loss: 1.6186 - acc: 0.7083\n",
      "Epoch 192/500\n",
      " - 0s - loss: 1.6043 - acc: 0.7083\n",
      "Epoch 193/500\n",
      " - 0s - loss: 1.5901 - acc: 0.7083\n",
      "Epoch 194/500\n",
      " - 0s - loss: 1.5759 - acc: 0.7083\n",
      "Epoch 195/500\n",
      " - 0s - loss: 1.5618 - acc: 0.7500\n",
      "Epoch 196/500\n",
      " - 0s - loss: 1.5478 - acc: 0.7500\n",
      "Epoch 197/500\n",
      " - 0s - loss: 1.5338 - acc: 0.7500\n",
      "Epoch 198/500\n",
      " - 0s - loss: 1.5199 - acc: 0.7500\n",
      "Epoch 199/500\n",
      " - 0s - loss: 1.5060 - acc: 0.7500\n",
      "Epoch 200/500\n",
      " - 0s - loss: 1.4922 - acc: 0.7500\n",
      "Epoch 201/500\n",
      " - 0s - loss: 1.4785 - acc: 0.8333\n",
      "Epoch 202/500\n",
      " - 0s - loss: 1.4648 - acc: 0.8333\n",
      "Epoch 203/500\n",
      " - 0s - loss: 1.4512 - acc: 0.8333\n",
      "Epoch 204/500\n",
      " - 0s - loss: 1.4377 - acc: 0.8333\n",
      "Epoch 205/500\n",
      " - 0s - loss: 1.4242 - acc: 0.8333\n",
      "Epoch 206/500\n",
      " - 0s - loss: 1.4108 - acc: 0.8333\n",
      "Epoch 207/500\n",
      " - 0s - loss: 1.3975 - acc: 0.8333\n",
      "Epoch 208/500\n",
      " - 0s - loss: 1.3842 - acc: 0.8333\n",
      "Epoch 209/500\n",
      " - 0s - loss: 1.3710 - acc: 0.8333\n",
      "Epoch 210/500\n",
      " - 0s - loss: 1.3579 - acc: 0.8333\n",
      "Epoch 211/500\n",
      " - 0s - loss: 1.3449 - acc: 0.8333\n",
      "Epoch 212/500\n",
      " - 0s - loss: 1.3320 - acc: 0.8333\n",
      "Epoch 213/500\n",
      " - 0s - loss: 1.3191 - acc: 0.8333\n",
      "Epoch 214/500\n",
      " - 0s - loss: 1.3063 - acc: 0.8333\n",
      "Epoch 215/500\n",
      " - 0s - loss: 1.2936 - acc: 0.8333\n",
      "Epoch 216/500\n",
      " - 0s - loss: 1.2809 - acc: 0.8333\n",
      "Epoch 217/500\n",
      " - 0s - loss: 1.2684 - acc: 0.8333\n",
      "Epoch 218/500\n",
      " - 0s - loss: 1.2559 - acc: 0.8333\n",
      "Epoch 219/500\n",
      " - 0s - loss: 1.2435 - acc: 0.8750\n",
      "Epoch 220/500\n",
      " - 0s - loss: 1.2312 - acc: 0.8750\n",
      "Epoch 221/500\n",
      " - 0s - loss: 1.2190 - acc: 0.8750\n",
      "Epoch 222/500\n",
      " - 0s - loss: 1.2069 - acc: 0.8750\n",
      "Epoch 223/500\n",
      " - 0s - loss: 1.1949 - acc: 0.8750\n",
      "Epoch 224/500\n",
      " - 0s - loss: 1.1829 - acc: 0.8750\n",
      "Epoch 225/500\n",
      " - 0s - loss: 1.1711 - acc: 0.8750\n",
      "Epoch 226/500\n",
      " - 0s - loss: 1.1593 - acc: 0.8750\n",
      "Epoch 227/500\n",
      " - 0s - loss: 1.1477 - acc: 0.8750\n",
      "Epoch 228/500\n",
      " - 0s - loss: 1.1361 - acc: 0.8750\n",
      "Epoch 229/500\n",
      " - 0s - loss: 1.1246 - acc: 0.8750\n",
      "Epoch 230/500\n",
      " - 0s - loss: 1.1133 - acc: 0.8750\n",
      "Epoch 231/500\n",
      " - 0s - loss: 1.1020 - acc: 0.8750\n",
      "Epoch 232/500\n",
      " - 0s - loss: 1.0908 - acc: 0.8750\n",
      "Epoch 233/500\n",
      " - 0s - loss: 1.0797 - acc: 0.8750\n",
      "Epoch 234/500\n",
      " - 0s - loss: 1.0688 - acc: 0.8750\n",
      "Epoch 235/500\n",
      " - 0s - loss: 1.0579 - acc: 0.8750\n",
      "Epoch 236/500\n",
      " - 0s - loss: 1.0471 - acc: 0.8750\n",
      "Epoch 237/500\n",
      " - 0s - loss: 1.0365 - acc: 0.8750\n",
      "Epoch 238/500\n",
      " - 0s - loss: 1.0259 - acc: 0.8750\n",
      "Epoch 239/500\n",
      " - 0s - loss: 1.0154 - acc: 0.8750\n",
      "Epoch 240/500\n",
      " - 0s - loss: 1.0051 - acc: 0.8750\n",
      "Epoch 241/500\n",
      " - 0s - loss: 0.9948 - acc: 0.8750\n",
      "Epoch 242/500\n",
      " - 0s - loss: 0.9846 - acc: 0.8750\n",
      "Epoch 243/500\n",
      " - 0s - loss: 0.9746 - acc: 0.8750\n",
      "Epoch 244/500\n",
      " - 0s - loss: 0.9646 - acc: 0.8750\n",
      "Epoch 245/500\n",
      " - 0s - loss: 0.9547 - acc: 0.8750\n",
      "Epoch 246/500\n",
      " - 0s - loss: 0.9450 - acc: 0.8750\n",
      "Epoch 247/500\n",
      " - 0s - loss: 0.9353 - acc: 0.8750\n",
      "Epoch 248/500\n",
      " - 0s - loss: 0.9258 - acc: 0.8750\n",
      "Epoch 249/500\n",
      " - 0s - loss: 0.9163 - acc: 0.8750\n",
      "Epoch 250/500\n",
      " - 0s - loss: 0.9070 - acc: 0.8750\n",
      "Epoch 251/500\n",
      " - 0s - loss: 0.8978 - acc: 0.8750\n",
      "Epoch 252/500\n",
      " - 0s - loss: 0.8886 - acc: 0.8750\n",
      "Epoch 253/500\n",
      " - 0s - loss: 0.8796 - acc: 0.8750\n",
      "Epoch 254/500\n",
      " - 0s - loss: 0.8707 - acc: 0.8750\n",
      "Epoch 255/500\n",
      " - 0s - loss: 0.8619 - acc: 0.8750\n",
      "Epoch 256/500\n",
      " - 0s - loss: 0.8532 - acc: 0.8750\n",
      "Epoch 257/500\n",
      " - 0s - loss: 0.8445 - acc: 0.8750\n",
      "Epoch 258/500\n",
      " - 0s - loss: 0.8360 - acc: 0.8750\n",
      "Epoch 259/500\n",
      " - 0s - loss: 0.8276 - acc: 0.8750\n",
      "Epoch 260/500\n",
      " - 0s - loss: 0.8193 - acc: 0.8750\n",
      "Epoch 261/500\n",
      " - 0s - loss: 0.8111 - acc: 0.8750\n",
      "Epoch 262/500\n",
      " - 0s - loss: 0.8030 - acc: 0.8750\n",
      "Epoch 263/500\n",
      " - 0s - loss: 0.7950 - acc: 0.8750\n",
      "Epoch 264/500\n",
      " - 0s - loss: 0.7871 - acc: 0.8750\n",
      "Epoch 265/500\n",
      " - 0s - loss: 0.7793 - acc: 0.8750\n",
      "Epoch 266/500\n",
      " - 0s - loss: 0.7715 - acc: 0.8750\n",
      "Epoch 267/500\n",
      " - 0s - loss: 0.7639 - acc: 0.8750\n",
      "Epoch 268/500\n",
      " - 0s - loss: 0.7564 - acc: 0.8750\n",
      "Epoch 269/500\n",
      " - 0s - loss: 0.7490 - acc: 0.8750\n",
      "Epoch 270/500\n",
      " - 0s - loss: 0.7416 - acc: 0.8750\n",
      "Epoch 271/500\n",
      " - 0s - loss: 0.7344 - acc: 0.8750\n",
      "Epoch 272/500\n",
      " - 0s - loss: 0.7272 - acc: 0.8750\n",
      "Epoch 273/500\n",
      " - 0s - loss: 0.7202 - acc: 0.8750\n",
      "Epoch 274/500\n",
      " - 0s - loss: 0.7132 - acc: 0.8750\n",
      "Epoch 275/500\n",
      " - 0s - loss: 0.7063 - acc: 0.8750\n",
      "Epoch 276/500\n",
      " - 0s - loss: 0.6995 - acc: 0.8750\n",
      "Epoch 277/500\n",
      " - 0s - loss: 0.6928 - acc: 0.8750\n",
      "Epoch 278/500\n",
      " - 0s - loss: 0.6862 - acc: 0.8750\n",
      "Epoch 279/500\n",
      " - 0s - loss: 0.6797 - acc: 0.8750\n",
      "Epoch 280/500\n",
      " - 0s - loss: 0.6732 - acc: 0.8750\n",
      "Epoch 281/500\n",
      " - 0s - loss: 0.6669 - acc: 0.8750\n",
      "Epoch 282/500\n",
      " - 0s - loss: 0.6606 - acc: 0.8750\n",
      "Epoch 283/500\n",
      " - 0s - loss: 0.6544 - acc: 0.8750\n",
      "Epoch 284/500\n",
      " - 0s - loss: 0.6483 - acc: 0.8750\n",
      "Epoch 285/500\n",
      " - 0s - loss: 0.6423 - acc: 0.8750\n",
      "Epoch 286/500\n",
      " - 0s - loss: 0.6363 - acc: 0.8750\n",
      "Epoch 287/500\n",
      " - 0s - loss: 0.6304 - acc: 0.8750\n",
      "Epoch 288/500\n",
      " - 0s - loss: 0.6246 - acc: 0.8750\n",
      "Epoch 289/500\n",
      " - 0s - loss: 0.6189 - acc: 0.8750\n",
      "Epoch 290/500\n",
      " - 0s - loss: 0.6133 - acc: 0.8750\n",
      "Epoch 291/500\n",
      " - 0s - loss: 0.6077 - acc: 0.8750\n",
      "Epoch 292/500\n",
      " - 0s - loss: 0.6022 - acc: 0.8750\n",
      "Epoch 293/500\n",
      " - 0s - loss: 0.5968 - acc: 0.8750\n",
      "Epoch 294/500\n",
      " - 0s - loss: 0.5914 - acc: 0.8750\n",
      "Epoch 295/500\n",
      " - 0s - loss: 0.5862 - acc: 0.8750\n",
      "Epoch 296/500\n",
      " - 0s - loss: 0.5810 - acc: 0.8750\n",
      "Epoch 297/500\n",
      " - 0s - loss: 0.5758 - acc: 0.8750\n",
      "Epoch 298/500\n",
      " - 0s - loss: 0.5708 - acc: 0.8750\n",
      "Epoch 299/500\n",
      " - 0s - loss: 0.5658 - acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500\n",
      " - 0s - loss: 0.5608 - acc: 0.8750\n",
      "Epoch 301/500\n",
      " - 0s - loss: 0.5560 - acc: 0.8750\n",
      "Epoch 302/500\n",
      " - 0s - loss: 0.5512 - acc: 0.8750\n",
      "Epoch 303/500\n",
      " - 0s - loss: 0.5464 - acc: 0.8750\n",
      "Epoch 304/500\n",
      " - 0s - loss: 0.5418 - acc: 0.8750\n",
      "Epoch 305/500\n",
      " - 0s - loss: 0.5372 - acc: 0.8750\n",
      "Epoch 306/500\n",
      " - 0s - loss: 0.5326 - acc: 0.8750\n",
      "Epoch 307/500\n",
      " - 0s - loss: 0.5281 - acc: 0.8750\n",
      "Epoch 308/500\n",
      " - 0s - loss: 0.5237 - acc: 0.8750\n",
      "Epoch 309/500\n",
      " - 0s - loss: 0.5193 - acc: 0.8750\n",
      "Epoch 310/500\n",
      " - 0s - loss: 0.5150 - acc: 0.8750\n",
      "Epoch 311/500\n",
      " - 0s - loss: 0.5108 - acc: 0.8750\n",
      "Epoch 312/500\n",
      " - 0s - loss: 0.5066 - acc: 0.8750\n",
      "Epoch 313/500\n",
      " - 0s - loss: 0.5025 - acc: 0.8750\n",
      "Epoch 314/500\n",
      " - 0s - loss: 0.4984 - acc: 0.8750\n",
      "Epoch 315/500\n",
      " - 0s - loss: 0.4944 - acc: 0.8750\n",
      "Epoch 316/500\n",
      " - 0s - loss: 0.4905 - acc: 0.8750\n",
      "Epoch 317/500\n",
      " - 0s - loss: 0.4866 - acc: 0.8750\n",
      "Epoch 318/500\n",
      " - 0s - loss: 0.4827 - acc: 0.8750\n",
      "Epoch 319/500\n",
      " - 0s - loss: 0.4790 - acc: 0.8750\n",
      "Epoch 320/500\n",
      " - 0s - loss: 0.4752 - acc: 0.8750\n",
      "Epoch 321/500\n",
      " - 0s - loss: 0.4716 - acc: 0.8750\n",
      "Epoch 322/500\n",
      " - 0s - loss: 0.4679 - acc: 0.8750\n",
      "Epoch 323/500\n",
      " - 0s - loss: 0.4644 - acc: 0.8750\n",
      "Epoch 324/500\n",
      " - 0s - loss: 0.4608 - acc: 0.8750\n",
      "Epoch 325/500\n",
      " - 0s - loss: 0.4574 - acc: 0.8750\n",
      "Epoch 326/500\n",
      " - 0s - loss: 0.4540 - acc: 0.8750\n",
      "Epoch 327/500\n",
      " - 0s - loss: 0.4506 - acc: 0.8750\n",
      "Epoch 328/500\n",
      " - 0s - loss: 0.4473 - acc: 0.8750\n",
      "Epoch 329/500\n",
      " - 0s - loss: 0.4440 - acc: 0.8750\n",
      "Epoch 330/500\n",
      " - 0s - loss: 0.4408 - acc: 0.8750\n",
      "Epoch 331/500\n",
      " - 0s - loss: 0.4376 - acc: 0.8750\n",
      "Epoch 332/500\n",
      " - 0s - loss: 0.4345 - acc: 0.8750\n",
      "Epoch 333/500\n",
      " - 0s - loss: 0.4314 - acc: 0.8750\n",
      "Epoch 334/500\n",
      " - 0s - loss: 0.4284 - acc: 0.8750\n",
      "Epoch 335/500\n",
      " - 0s - loss: 0.4254 - acc: 0.8750\n",
      "Epoch 336/500\n",
      " - 0s - loss: 0.4224 - acc: 0.8750\n",
      "Epoch 337/500\n",
      " - 0s - loss: 0.4195 - acc: 0.8750\n",
      "Epoch 338/500\n",
      " - 0s - loss: 0.4166 - acc: 0.8750\n",
      "Epoch 339/500\n",
      " - 0s - loss: 0.4138 - acc: 0.8750\n",
      "Epoch 340/500\n",
      " - 0s - loss: 0.4110 - acc: 0.8750\n",
      "Epoch 341/500\n",
      " - 0s - loss: 0.4083 - acc: 0.8750\n",
      "Epoch 342/500\n",
      " - 0s - loss: 0.4056 - acc: 0.8750\n",
      "Epoch 343/500\n",
      " - 0s - loss: 0.4029 - acc: 0.8750\n",
      "Epoch 344/500\n",
      " - 0s - loss: 0.4003 - acc: 0.8750\n",
      "Epoch 345/500\n",
      " - 0s - loss: 0.3977 - acc: 0.8750\n",
      "Epoch 346/500\n",
      " - 0s - loss: 0.3951 - acc: 0.8750\n",
      "Epoch 347/500\n",
      " - 0s - loss: 0.3926 - acc: 0.8750\n",
      "Epoch 348/500\n",
      " - 0s - loss: 0.3901 - acc: 0.8750\n",
      "Epoch 349/500\n",
      " - 0s - loss: 0.3877 - acc: 0.8750\n",
      "Epoch 350/500\n",
      " - 0s - loss: 0.3853 - acc: 0.8750\n",
      "Epoch 351/500\n",
      " - 0s - loss: 0.3829 - acc: 0.8750\n",
      "Epoch 352/500\n",
      " - 0s - loss: 0.3805 - acc: 0.8750\n",
      "Epoch 353/500\n",
      " - 0s - loss: 0.3782 - acc: 0.8750\n",
      "Epoch 354/500\n",
      " - 0s - loss: 0.3760 - acc: 0.8750\n",
      "Epoch 355/500\n",
      " - 0s - loss: 0.3737 - acc: 0.8750\n",
      "Epoch 356/500\n",
      " - 0s - loss: 0.3715 - acc: 0.8750\n",
      "Epoch 357/500\n",
      " - 0s - loss: 0.3694 - acc: 0.8750\n",
      "Epoch 358/500\n",
      " - 0s - loss: 0.3672 - acc: 0.8750\n",
      "Epoch 359/500\n",
      " - 0s - loss: 0.3651 - acc: 0.8750\n",
      "Epoch 360/500\n",
      " - 0s - loss: 0.3631 - acc: 0.8750\n",
      "Epoch 361/500\n",
      " - 0s - loss: 0.3610 - acc: 0.8750\n",
      "Epoch 362/500\n",
      " - 0s - loss: 0.3590 - acc: 0.8750\n",
      "Epoch 363/500\n",
      " - 0s - loss: 0.3570 - acc: 0.8750\n",
      "Epoch 364/500\n",
      " - 0s - loss: 0.3551 - acc: 0.8750\n",
      "Epoch 365/500\n",
      " - 0s - loss: 0.3531 - acc: 0.8750\n",
      "Epoch 366/500\n",
      " - 0s - loss: 0.3512 - acc: 0.8750\n",
      "Epoch 367/500\n",
      " - 0s - loss: 0.3494 - acc: 0.8750\n",
      "Epoch 368/500\n",
      " - 0s - loss: 0.3475 - acc: 0.8750\n",
      "Epoch 369/500\n",
      " - 0s - loss: 0.3457 - acc: 0.8750\n",
      "Epoch 370/500\n",
      " - 0s - loss: 0.3439 - acc: 0.8750\n",
      "Epoch 371/500\n",
      " - 0s - loss: 0.3422 - acc: 0.8750\n",
      "Epoch 372/500\n",
      " - 0s - loss: 0.3404 - acc: 0.8750\n",
      "Epoch 373/500\n",
      " - 0s - loss: 0.3387 - acc: 0.8750\n",
      "Epoch 374/500\n",
      " - 0s - loss: 0.3370 - acc: 0.8750\n",
      "Epoch 375/500\n",
      " - 0s - loss: 0.3354 - acc: 0.8750\n",
      "Epoch 376/500\n",
      " - 0s - loss: 0.3337 - acc: 0.8750\n",
      "Epoch 377/500\n",
      " - 0s - loss: 0.3321 - acc: 0.8750\n",
      "Epoch 378/500\n",
      " - 0s - loss: 0.3305 - acc: 0.8750\n",
      "Epoch 379/500\n",
      " - 0s - loss: 0.3289 - acc: 0.8750\n",
      "Epoch 380/500\n",
      " - 0s - loss: 0.3274 - acc: 0.8750\n",
      "Epoch 381/500\n",
      " - 0s - loss: 0.3259 - acc: 0.8750\n",
      "Epoch 382/500\n",
      " - 0s - loss: 0.3244 - acc: 0.8750\n",
      "Epoch 383/500\n",
      " - 0s - loss: 0.3229 - acc: 0.8750\n",
      "Epoch 384/500\n",
      " - 0s - loss: 0.3214 - acc: 0.8750\n",
      "Epoch 385/500\n",
      " - 0s - loss: 0.3200 - acc: 0.8750\n",
      "Epoch 386/500\n",
      " - 0s - loss: 0.3186 - acc: 0.8750\n",
      "Epoch 387/500\n",
      " - 0s - loss: 0.3172 - acc: 0.8750\n",
      "Epoch 388/500\n",
      " - 0s - loss: 0.3158 - acc: 0.8750\n",
      "Epoch 389/500\n",
      " - 0s - loss: 0.3144 - acc: 0.8750\n",
      "Epoch 390/500\n",
      " - 0s - loss: 0.3131 - acc: 0.8750\n",
      "Epoch 391/500\n",
      " - 0s - loss: 0.3118 - acc: 0.8750\n",
      "Epoch 392/500\n",
      " - 0s - loss: 0.3105 - acc: 0.8750\n",
      "Epoch 393/500\n",
      " - 0s - loss: 0.3092 - acc: 0.8750\n",
      "Epoch 394/500\n",
      " - 0s - loss: 0.3079 - acc: 0.8750\n",
      "Epoch 395/500\n",
      " - 0s - loss: 0.3067 - acc: 0.8750\n",
      "Epoch 396/500\n",
      " - 0s - loss: 0.3055 - acc: 0.8750\n",
      "Epoch 397/500\n",
      " - 0s - loss: 0.3043 - acc: 0.8750\n",
      "Epoch 398/500\n",
      " - 0s - loss: 0.3031 - acc: 0.8750\n",
      "Epoch 399/500\n",
      " - 0s - loss: 0.3019 - acc: 0.8750\n",
      "Epoch 400/500\n",
      " - 0s - loss: 0.3007 - acc: 0.8750\n",
      "Epoch 401/500\n",
      " - 0s - loss: 0.2996 - acc: 0.8750\n",
      "Epoch 402/500\n",
      " - 0s - loss: 0.2985 - acc: 0.8750\n",
      "Epoch 403/500\n",
      " - 0s - loss: 0.2974 - acc: 0.8750\n",
      "Epoch 404/500\n",
      " - 0s - loss: 0.2963 - acc: 0.8750\n",
      "Epoch 405/500\n",
      " - 0s - loss: 0.2952 - acc: 0.8750\n",
      "Epoch 406/500\n",
      " - 0s - loss: 0.2941 - acc: 0.8750\n",
      "Epoch 407/500\n",
      " - 0s - loss: 0.2931 - acc: 0.8750\n",
      "Epoch 408/500\n",
      " - 0s - loss: 0.2920 - acc: 0.8750\n",
      "Epoch 409/500\n",
      " - 0s - loss: 0.2910 - acc: 0.8750\n",
      "Epoch 410/500\n",
      " - 0s - loss: 0.2900 - acc: 0.8750\n",
      "Epoch 411/500\n",
      " - 0s - loss: 0.2890 - acc: 0.8750\n",
      "Epoch 412/500\n",
      " - 0s - loss: 0.2881 - acc: 0.8750\n",
      "Epoch 413/500\n",
      " - 0s - loss: 0.2871 - acc: 0.8750\n",
      "Epoch 414/500\n",
      " - 0s - loss: 0.2862 - acc: 0.8750\n",
      "Epoch 415/500\n",
      " - 0s - loss: 0.2852 - acc: 0.8750\n",
      "Epoch 416/500\n",
      " - 0s - loss: 0.2843 - acc: 0.8750\n",
      "Epoch 417/500\n",
      " - 0s - loss: 0.2834 - acc: 0.8750\n",
      "Epoch 418/500\n",
      " - 0s - loss: 0.2825 - acc: 0.8750\n",
      "Epoch 419/500\n",
      " - 0s - loss: 0.2816 - acc: 0.8750\n",
      "Epoch 420/500\n",
      " - 0s - loss: 0.2808 - acc: 0.8750\n",
      "Epoch 421/500\n",
      " - 0s - loss: 0.2799 - acc: 0.8750\n",
      "Epoch 422/500\n",
      " - 0s - loss: 0.2791 - acc: 0.8750\n",
      "Epoch 423/500\n",
      " - 0s - loss: 0.2782 - acc: 0.8750\n",
      "Epoch 424/500\n",
      " - 0s - loss: 0.2774 - acc: 0.8750\n",
      "Epoch 425/500\n",
      " - 0s - loss: 0.2766 - acc: 0.8750\n",
      "Epoch 426/500\n",
      " - 0s - loss: 0.2758 - acc: 0.8750\n",
      "Epoch 427/500\n",
      " - 0s - loss: 0.2750 - acc: 0.8750\n",
      "Epoch 428/500\n",
      " - 0s - loss: 0.2742 - acc: 0.8750\n",
      "Epoch 429/500\n",
      " - 0s - loss: 0.2735 - acc: 0.8750\n",
      "Epoch 430/500\n",
      " - 0s - loss: 0.2727 - acc: 0.8750\n",
      "Epoch 431/500\n",
      " - 0s - loss: 0.2720 - acc: 0.8750\n",
      "Epoch 432/500\n",
      " - 0s - loss: 0.2712 - acc: 0.8750\n",
      "Epoch 433/500\n",
      " - 0s - loss: 0.2705 - acc: 0.8750\n",
      "Epoch 434/500\n",
      " - 0s - loss: 0.2698 - acc: 0.8750\n",
      "Epoch 435/500\n",
      " - 0s - loss: 0.2691 - acc: 0.8750\n",
      "Epoch 436/500\n",
      " - 0s - loss: 0.2684 - acc: 0.8750\n",
      "Epoch 437/500\n",
      " - 0s - loss: 0.2677 - acc: 0.8750\n",
      "Epoch 438/500\n",
      " - 0s - loss: 0.2670 - acc: 0.8750\n",
      "Epoch 439/500\n",
      " - 0s - loss: 0.2664 - acc: 0.8750\n",
      "Epoch 440/500\n",
      " - 0s - loss: 0.2657 - acc: 0.8750\n",
      "Epoch 441/500\n",
      " - 0s - loss: 0.2651 - acc: 0.8750\n",
      "Epoch 442/500\n",
      " - 0s - loss: 0.2644 - acc: 0.8750\n",
      "Epoch 443/500\n",
      " - 0s - loss: 0.2638 - acc: 0.8750\n",
      "Epoch 444/500\n",
      " - 0s - loss: 0.2632 - acc: 0.8750\n",
      "Epoch 445/500\n",
      " - 0s - loss: 0.2626 - acc: 0.8750\n",
      "Epoch 446/500\n",
      " - 0s - loss: 0.2620 - acc: 0.8750\n",
      "Epoch 447/500\n",
      " - 0s - loss: 0.2614 - acc: 0.8750\n",
      "Epoch 448/500\n",
      " - 0s - loss: 0.2608 - acc: 0.8750\n",
      "Epoch 449/500\n",
      " - 0s - loss: 0.2602 - acc: 0.8750\n",
      "Epoch 450/500\n",
      " - 0s - loss: 0.2596 - acc: 0.8750\n",
      "Epoch 451/500\n",
      " - 0s - loss: 0.2590 - acc: 0.8750\n",
      "Epoch 452/500\n",
      " - 0s - loss: 0.2585 - acc: 0.8750\n",
      "Epoch 453/500\n",
      " - 0s - loss: 0.2579 - acc: 0.8750\n",
      "Epoch 454/500\n",
      " - 0s - loss: 0.2574 - acc: 0.8750\n",
      "Epoch 455/500\n",
      " - 0s - loss: 0.2569 - acc: 0.8750\n",
      "Epoch 456/500\n",
      " - 0s - loss: 0.2563 - acc: 0.8750\n",
      "Epoch 457/500\n",
      " - 0s - loss: 0.2558 - acc: 0.8750\n",
      "Epoch 458/500\n",
      " - 0s - loss: 0.2553 - acc: 0.8750\n",
      "Epoch 459/500\n",
      " - 0s - loss: 0.2548 - acc: 0.8750\n",
      "Epoch 460/500\n",
      " - 0s - loss: 0.2543 - acc: 0.8750\n",
      "Epoch 461/500\n",
      " - 0s - loss: 0.2538 - acc: 0.8750\n",
      "Epoch 462/500\n",
      " - 0s - loss: 0.2533 - acc: 0.8750\n",
      "Epoch 463/500\n",
      " - 0s - loss: 0.2528 - acc: 0.8750\n",
      "Epoch 464/500\n",
      " - 0s - loss: 0.2523 - acc: 0.8750\n",
      "Epoch 465/500\n",
      " - 0s - loss: 0.2518 - acc: 0.8750\n",
      "Epoch 466/500\n",
      " - 0s - loss: 0.2514 - acc: 0.8750\n",
      "Epoch 467/500\n",
      " - 0s - loss: 0.2509 - acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/500\n",
      " - 0s - loss: 0.2504 - acc: 0.8750\n",
      "Epoch 469/500\n",
      " - 0s - loss: 0.2500 - acc: 0.8750\n",
      "Epoch 470/500\n",
      " - 0s - loss: 0.2495 - acc: 0.8750\n",
      "Epoch 471/500\n",
      " - 0s - loss: 0.2491 - acc: 0.8750\n",
      "Epoch 472/500\n",
      " - 0s - loss: 0.2487 - acc: 0.8750\n",
      "Epoch 473/500\n",
      " - 0s - loss: 0.2482 - acc: 0.8750\n",
      "Epoch 474/500\n",
      " - 0s - loss: 0.2478 - acc: 0.8750\n",
      "Epoch 475/500\n",
      " - 0s - loss: 0.2474 - acc: 0.8750\n",
      "Epoch 476/500\n",
      " - 0s - loss: 0.2470 - acc: 0.8750\n",
      "Epoch 477/500\n",
      " - 0s - loss: 0.2466 - acc: 0.8750\n",
      "Epoch 478/500\n",
      " - 0s - loss: 0.2462 - acc: 0.8750\n",
      "Epoch 479/500\n",
      " - 0s - loss: 0.2458 - acc: 0.8750\n",
      "Epoch 480/500\n",
      " - 0s - loss: 0.2454 - acc: 0.8750\n",
      "Epoch 481/500\n",
      " - 0s - loss: 0.2450 - acc: 0.8750\n",
      "Epoch 482/500\n",
      " - 0s - loss: 0.2446 - acc: 0.8750\n",
      "Epoch 483/500\n",
      " - 0s - loss: 0.2442 - acc: 0.8750\n",
      "Epoch 484/500\n",
      " - 0s - loss: 0.2438 - acc: 0.8750\n",
      "Epoch 485/500\n",
      " - 0s - loss: 0.2435 - acc: 0.8750\n",
      "Epoch 486/500\n",
      " - 0s - loss: 0.2431 - acc: 0.8750\n",
      "Epoch 487/500\n",
      " - 0s - loss: 0.2427 - acc: 0.8750\n",
      "Epoch 488/500\n",
      " - 0s - loss: 0.2424 - acc: 0.8750\n",
      "Epoch 489/500\n",
      " - 0s - loss: 0.2420 - acc: 0.8750\n",
      "Epoch 490/500\n",
      " - 0s - loss: 0.2417 - acc: 0.8750\n",
      "Epoch 491/500\n",
      " - 0s - loss: 0.2413 - acc: 0.8750\n",
      "Epoch 492/500\n",
      " - 0s - loss: 0.2410 - acc: 0.8750\n",
      "Epoch 493/500\n",
      " - 0s - loss: 0.2406 - acc: 0.8750\n",
      "Epoch 494/500\n",
      " - 0s - loss: 0.2403 - acc: 0.8750\n",
      "Epoch 495/500\n",
      " - 0s - loss: 0.2399 - acc: 0.8750\n",
      "Epoch 496/500\n",
      " - 0s - loss: 0.2396 - acc: 0.8750\n",
      "Epoch 497/500\n",
      " - 0s - loss: 0.2393 - acc: 0.8750\n",
      "Epoch 498/500\n",
      " - 0s - loss: 0.2390 - acc: 0.8750\n",
      "Epoch 499/500\n",
      " - 0s - loss: 0.2387 - acc: 0.8750\n",
      "Epoch 500/500\n",
      " - 0s - loss: 0.2383 - acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x263d4cbc0c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(X, y, epochs=500, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from the model\n",
    "def generate_seq(model, tokenizer, seed_text, n_words):\n",
    "    in_text, result = seed_text, seed_text\n",
    "    for _ in range(n_words):\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        encoded = array(encoded)\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text, result = out_word, result + ' ' + out_word\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack and jill came tumbling after a\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "print(generate_seq(model, tokenizer, 'Jack', 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
